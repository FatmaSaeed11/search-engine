{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              *****    Documents     ***** \n",
      "antony brutus caeser cleopatra mercy worser\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antony brutus caeser calpurnia \n",
      "mercy worser\n",
      "brutus caeser mercy worser\n",
      "caeser mercy worser\n",
      "antony caeser mercy \n",
      "angels fools fear in rush to tread where\n",
      "angels fools fear in rush to tread where\n",
      "angels fools in rush to tread where\n",
      "fools fear in rush to tread where\n",
      "                                               *****    Documents in  Terms   *****                                                                        \n",
      "     [['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser'], ['antony', 'brutus', 'caeser', 'calpurnia'], ['mercy', 'worser'], ['brutus', 'caeser', 'mercy', 'worser'], ['caeser', 'mercy', 'worser'], ['antony', 'caeser', 'mercy'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'in', 'rush', 'to', 'tread', 'where'], ['fools', 'fear', 'in', 'rush', 'to', 'tread', 'where']] \n",
      "\n",
      "\n",
      "                                               *****     positions    *****                                       \n",
      "   \n",
      "{'antony': [3, {0: [0], 1: [0], 5: [0]}], 'brutus': [3, {0: [1], 1: [1], 3: [0]}], 'caeser': [5, {0: [2], 1: [2], 3: [1], 4: [0], 5: [1]}], 'cleopatra': [1, {0: [3]}], 'mercy': [5, {0: [4], 2: [0], 3: [2], 4: [1], 5: [2]}], 'worser': [4, {0: [5], 2: [1], 3: [3], 4: [2]}], 'calpurnia': [1, {1: [3]}], 'angels': [3, {6: [0], 7: [0], 8: [0]}], 'fools': [4, {6: [1], 7: [1], 8: [1], 9: [0]}], 'fear': [3, {6: [2], 7: [2], 9: [1]}], 'in': [4, {6: [3], 7: [3], 8: [2], 9: [2]}], 'rush': [4, {6: [4], 7: [4], 8: [3], 9: [3]}], 'to': [4, {6: [5], 7: [5], 8: [4], 9: [4]}], 'tread': [4, {6: [6], 7: [6], 8: [5], 9: [5]}], 'where': [4, {6: [7], 7: [7], 8: [6], 9: [6]}]} \n",
      "\n",
      "                                    ***** all response list *****                                                     \n",
      "[[], [], [], [], [], [], [1, 2], [1, 2], [1], [0, 1]] \n",
      "\n",
      "                                  *****response list to query*****                                              \n",
      "7 [1, 2]\n",
      "8 [1, 2]\n",
      "10 [0, 1]\n",
      "                                  *****term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony        1     1     0     0     0     1     0     0     0      0\n",
      "brutus        1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "mercy         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angels        0     0     0     0     0     0     1     1     1      0\n",
      "fools         0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "                                  ***** weighted term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutus      1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "mercy       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angels      0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fools       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0 \n",
      "\n",
      "\n",
      "                                  *****        IDF          *****                                              \n",
      "            df       idf\n",
      "antony     3.0  0.522879\n",
      "brutus     3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "mercy      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angels     3.0  0.522879\n",
      "fools      4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "                                  *****         TF*IDF             *****                                              \n",
      "\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antony     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutus     0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "mercy       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angels          0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fools           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antony          0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angels     0.522879  0.522879       0.0  \n",
      "fools       0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "                                  *****         Doc Length             *****                                              \n",
      "\n",
      "   doc1_length  doc2_length  doc3_length  doc4_length  doc5_length  \\\n",
      "0     1.373462     1.279618     0.498974     0.782941     0.582747   \n",
      "\n",
      "   doc6_length  doc7_length  doc8_length  doc9_length  doc10_length  \n",
      "0      0.67427     1.223496     1.223496     1.106137      1.106137   \n",
      "\n",
      "                                  *****        Normalized TF*IDF           *****                                              \n",
      "\n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "antony     0.380701  0.408621       0.0       0.0       0.0  0.775474   \n",
      "brutus     0.380701  0.408621       0.0  0.667839       0.0       0.0   \n",
      "caeser     0.219176   0.23525       0.0  0.384486   0.51657  0.446453   \n",
      "cleopatra  0.728087       0.0       0.0       0.0       0.0       0.0   \n",
      "mercy      0.219176       0.0  0.603298  0.384486   0.51657  0.446453   \n",
      "worser     0.289735       0.0  0.797516  0.508263  0.682869       0.0   \n",
      "calpurnia       0.0  0.781483       0.0       0.0       0.0       0.0   \n",
      "angels          0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "fools           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "fear            0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "in              0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "rush            0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "to              0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "tread           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "where           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "antony          0.0       0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0       0.0  \n",
      "angels     0.427365  0.427365  0.472707       0.0  \n",
      "fools      0.325248  0.325248  0.359756  0.359756  \n",
      "fear       0.427365  0.427365       0.0  0.472707  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from natsort import natsorted\n",
    "from nltk.stem import PorterStemmer\n",
    "#preprocessing\n",
    "       \n",
    "files_name=natsorted(os.listdir('files'))\n",
    "print('                                              *****    Documents     ***** ' )\n",
    "document_of_terms=[]\n",
    "for files in files_name:\n",
    "    with open(f'files/{files}','r') as f:\n",
    "        document=f.read()\n",
    "        \n",
    "        print(document)\n",
    " \n",
    "    tokenized_documents=word_tokenize(document)\n",
    "    terms=[]\n",
    "    for word in tokenized_documents:\n",
    "            terms.append(word)\n",
    "    document_of_terms.append(terms)\n",
    "\n",
    "print('                                               *****    Documents in  Terms   *****                                                                        \\n    '\n",
    "    ,  document_of_terms,'\\n')                        \n",
    "\n",
    "######### \n",
    "#positional_index\n",
    "\n",
    "document_number = 0\n",
    "positional_index = {}\n",
    "\n",
    "print() \n",
    "print(\"                                               *****     positions    *****                                       \\n   \")\n",
    "for document in document_of_terms:\n",
    "    for positional, term in enumerate(document):\n",
    "        if term in positional_index:\n",
    "            positional_index[term][0] = positional_index[term][0] + 1\n",
    "\n",
    "            if document_number in positional_index[term][1]:\n",
    "                positional_index[term][1][document_number].append(positional)\n",
    "            else:\n",
    "                positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "        else:\n",
    "            positional_index[term] = []\n",
    "            positional_index[term].append(1)\n",
    "            positional_index[term].append({})\n",
    "            positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "    document_number += 1\n",
    "    \n",
    "\n",
    "print(positional_index,'\\n')\n",
    "\n",
    "#query_preprocessing\n",
    "\n",
    "query='fools fear'\n",
    "\n",
    "final_list=[[]for i in range (10)]\n",
    "print('                                    ***** all response list *****                                                     ')\n",
    "for word in query.split():    \n",
    "    if word in positional_index.keys():\n",
    "        for key in positional_index[word][1].keys():\n",
    "            #print(key)\n",
    "            if final_list[key]!=[]:\n",
    "                \n",
    "                 if final_list[key][-1] == positional_index[word][1][key][0]-1:\n",
    "                        final_list[key].append(positional_index[word][1][key][0])\n",
    "        \n",
    "            else:\n",
    "                 final_list[key].append(positional_index[word][1][key][0])\n",
    "            \n",
    "print(final_list,'\\n')\n",
    "\n",
    "print('                                  *****response list to query*****                                              ')\n",
    "for position,list in enumerate(final_list,start=1):\n",
    "    if len(list)==len(query.split()):\n",
    "      print(position,list)     \n",
    "\n",
    "\n",
    "#find tf and wtf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "all_words=[]\n",
    "for doc in document_of_terms:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    " #tf       \n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(all_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word]+=1\n",
    "    return words_found\n",
    "\n",
    "term_freq=pd.DataFrame(get_term_freq(document_of_terms[0]).values(),index=get_term_freq(document_of_terms[0]).keys())              \n",
    "print('                                  *****term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)):\n",
    "    term_freq[i]=get_term_freq(document_of_terms[i]).values()\n",
    "    \n",
    "term_freq.columns=['doc'+str(i) for i in range (1,11)]    \n",
    "print(term_freq)     \n",
    "\n",
    "#wtf\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x>0:\n",
    "      return math.log(x)+1\n",
    "    return 0\n",
    "     \n",
    "print('                                  ***** weighted term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)+1):\n",
    "    term_freq['doc'+str(i)]= term_freq['doc'+str(i)].apply(get_weighted_term_freq) \n",
    "    \n",
    "print(term_freq,'\\n')\n",
    "print()\n",
    " \n",
    "#idf and tf*idf\n",
    " \n",
    "tfd=pd.DataFrame(columns=['df','idf'])\n",
    "\n",
    "print('                                  *****        IDF          *****                                              ')\n",
    "for i in range(len(term_freq)):\n",
    "    \n",
    "    frequancy=term_freq.iloc[i].values.sum()\n",
    "    \n",
    "    tfd.loc[i,'df']=frequancy\n",
    "    tfd.loc[i,'idf']=math.log10(10/(float(frequancy)))\n",
    "    \n",
    "tfd.index=term_freq.index\n",
    "    \n",
    "print(tfd)\n",
    "# tf*idf\n",
    "\n",
    "tf_idf=term_freq.multiply(tfd['idf'],axis=0)\n",
    "\n",
    "print('                                  *****         TF*IDF             *****                                              ')\n",
    "print()      \n",
    "print(tf_idf)\n",
    "# doc length\n",
    "\n",
    "'''\n",
    "def get_documents_length(col):\n",
    "    return np.sqrt(tf_idf[col].apply(lambda x:x**2).sum())\n",
    "\n",
    "\n",
    "for column in tf_idf.columns:\n",
    "    document_length.loc[0,column+'_len']=get_documents_length(column)\n",
    "print('                                  *****         Doc Length             *****                                              ') \n",
    "print(document_length,'\\n')    \n",
    "\n",
    "\n",
    "# normalized tf*idf\n",
    "norm_tf_idf = pd.DataFrame()\n",
    "def get_normalized(col, x):\n",
    "    try:\n",
    "        return x / document_length[col + '__len'].values[0]\n",
    "    except:\n",
    "        return 0\n",
    "for column in tf_idf.columns:\n",
    "    norm_tf_idf[column] = tf_idf[column].apply(lambda x: get_normalized(column, x))\n",
    "\n",
    "print('                                  *****        Normalized TF*IDF           *****                                              ')\n",
    "print(norm_tf_idf, '\\n')\n",
    "'''\n",
    "\n",
    "document_length=pd.DataFrame({\n",
    "    f'doc{i}_length':np.sqrt(tf_idf[f'doc{i}'].apply(lambda x:x**2).sum()) for i in range (1,11)\n",
    "                             \n",
    "},index=[0])\n",
    "print('                                  *****         Doc Length             *****                                              ') \n",
    "print()\n",
    "print(document_length,'\\n') \n",
    "\n",
    "norm_tf_idf= tf_idf.divide(document_length.values[0],axis=1)\n",
    "print('                                  *****        Normalized TF*IDF           *****                                              ')\n",
    "print()\n",
    "print(norm_tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q='antony brutus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_tf(x):\n",
    "    try:\n",
    "        return math.log10(x)+1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\fatma\\level 4\\IR\\ir project\\insert_q.ipynb\\insert_q.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q.ipynb/insert_q.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q.ipynb/insert_q.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m query\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mnorm_tf_idf\u001b[39m.\u001b[39mindex)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q.ipynb/insert_q.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m query[\u001b[39m'\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m q\u001b[39m.\u001b[39msplit() \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39;49m(norm_tf_idf\u001b[39m.\u001b[39;49mindex)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q.ipynb/insert_q.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m query[\u001b[39m'\u001b[39m\u001b[39mw_tf\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mquery[\u001b[39m'\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:get_w_tf(x))\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q.ipynb/insert_q.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m product\u001b[39m=\u001b[39mnorm_tf_idf\u001b[39m.\u001b[39mmultiply(query[\u001b[39m'\u001b[39m\u001b[39mw_tf\u001b[39m\u001b[39m'\u001b[39m],axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "import math\n",
    "query=pd.DataFrame(index=norm_tf_idf.index)\n",
    "query['tf']=[1 if x in q.split() else 0 for x in list(norm_tf_idf.index)]\n",
    "query['w_tf']=query['tf'].apply(lambda x:get_w_tf(x))\n",
    "product=norm_tf_idf.multiply(query['w_tf'],axis=0)\n",
    "query['idf']=tfd['idf']*query['w_tf']\n",
    "query['tf_idf']=query['w_tf']*query['idf']\n",
    "query['norm']=0\n",
    "for i in range(len(query)):\n",
    "    query['norm'].iloc[i]=float(query['idf'].iloc[i])/math.sqrt(sum(query['idf'].values**2))\n",
    "\n",
    "product2=product.multiply(query['norm'],axis=0)   \n",
    "#product2\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7394622130520805"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(sum([x**2 for x in query['idf'].loc[q.split()]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "antony    0.522879\n",
       "brutus    0.522879\n",
       "Name: idf, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query['idf'].loc[q.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product2.loc[q.split()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores={}\n",
    "for col in product2.columns:\n",
    "    if 0 in product2[col].loc[q.split()].values:\n",
    "        pass\n",
    "    else:\n",
    "        scores[col]=product2[col].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [antony, brutus, caeser, cleopatra, mercy, worser, calpurnia, angels, fools, fear, in, rush, to, tread, where]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product2[list(scores.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [antony, brutus]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product2[list(scores.keys())].loc[q.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_res=product2[list(scores.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score=sorted(scores.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in final_score:\n",
    "    print(doc[0],end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
