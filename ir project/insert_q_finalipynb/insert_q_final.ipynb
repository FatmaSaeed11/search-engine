{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               *****    Documents in  Terms   *****                                                                        \n",
      "     [['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser'], ['antony', 'brutus', 'caeser', 'calpurnia'], ['mercy', 'worser'], ['brutus', 'caeser', 'mercy', 'worser'], ['caeser', 'mercy', 'worser'], ['antony', 'caeser', 'mercy'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'in', 'rush', 'to', 'tread', 'where'], ['fools', 'fear', 'in', 'rush', 'to', 'tread', 'where']] \n",
      "\n",
      "                                               *****     Stemmed Terms   *****                                                                        \n",
      "     [['antoni'], ['brutu'], ['caeser'], ['cleopatra'], ['merci'], ['worser'], ['antoni'], ['brutu'], ['caeser'], ['calpurnia'], ['merci'], ['worser'], ['brutu'], ['caeser'], ['merci'], ['worser'], ['caeser'], ['merci'], ['worser'], ['antoni'], ['caeser'], ['merci'], ['angel'], ['fool'], ['fear'], ['in'], ['rush'], ['to'], ['tread'], ['where'], ['angel'], ['fool'], ['fear'], ['in'], ['rush'], ['to'], ['tread'], ['where'], ['angel'], ['fool'], ['in'], ['rush'], ['to'], ['tread'], ['where'], ['fool'], ['fear'], ['in'], ['rush'], ['to'], ['tread'], ['where']] \n",
      "\n",
      "\n",
      "                                               *****     positions    *****                                       \n",
      "   \n",
      "{'antony': [3, {0: [0], 1: [0], 5: [0]}], 'brutus': [3, {0: [1], 1: [1], 3: [0]}], 'caeser': [5, {0: [2], 1: [2], 3: [1], 4: [0], 5: [1]}], 'cleopatra': [1, {0: [3]}], 'mercy': [5, {0: [4], 2: [0], 3: [2], 4: [1], 5: [2]}], 'worser': [4, {0: [5], 2: [1], 3: [3], 4: [2]}], 'calpurnia': [1, {1: [3]}], 'angels': [3, {6: [0], 7: [0], 8: [0]}], 'fools': [4, {6: [1], 7: [1], 8: [1], 9: [0]}], 'fear': [3, {6: [2], 7: [2], 9: [1]}], 'in': [4, {6: [3], 7: [3], 8: [2], 9: [2]}], 'rush': [4, {6: [4], 7: [4], 8: [3], 9: [3]}], 'to': [4, {6: [5], 7: [5], 8: [4], 9: [4]}], 'tread': [4, {6: [6], 7: [6], 8: [5], 9: [5]}], 'where': [4, {6: [7], 7: [7], 8: [6], 9: [6]}]} \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    ***** all response list *****                                                     \n",
      "[[0, 1], [0, 1], [], [0], [], [0], [], [], [], []] \n",
      "\n",
      "                                  *****response list to query*****                                              \n",
      "1 [0, 1]\n",
      "2 [0, 1]\n",
      "                                  *****term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony        1     1     0     0     0     1     0     0     0      0\n",
      "brutus        1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "mercy         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angels        0     0     0     0     0     0     1     1     1      0\n",
      "fools         0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "                                  ***** weighted term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutus      1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "mercy       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angels      0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fools       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0 \n",
      "\n",
      "\n",
      "                                  *****        IDF          *****                                              \n",
      "            df       idf\n",
      "antony     3.0  0.522879\n",
      "brutus     3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "mercy      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angels     3.0  0.522879\n",
      "fools      4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "                                  *****         TF*IDF             *****                                              \n",
      "\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antony     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutus     0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "mercy       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angels          0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fools           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antony          0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angels     0.522879  0.522879       0.0  \n",
      "fools       0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "                                  *****         Doc Length             *****                                              \n",
      "        doc1__length  doc2__length  doc3__length  doc4__length  doc5__length  \\\n",
      "length      1.373462      1.279618      0.498974      0.782941      0.582747   \n",
      "\n",
      "        doc6__length  doc7__length  doc8__length  doc9__length  doc10__length  \n",
      "length       0.67427      1.223496      1.223496      1.106137       1.106137   \n",
      "\n",
      "                                  *****        Normalized TF*IDF           *****                                              \n",
      "\n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "antony     0.380701  0.408621       0.0       0.0       0.0  0.775474   \n",
      "brutus     0.380701  0.408621       0.0  0.667839       0.0       0.0   \n",
      "caeser     0.219176   0.23525       0.0  0.384486   0.51657  0.446453   \n",
      "cleopatra  0.728087       0.0       0.0       0.0       0.0       0.0   \n",
      "mercy      0.219176       0.0  0.603298  0.384486   0.51657  0.446453   \n",
      "worser     0.289735       0.0  0.797516  0.508263  0.682869       0.0   \n",
      "calpurnia       0.0  0.781483       0.0       0.0       0.0       0.0   \n",
      "angels          0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "fools           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "fear            0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "in              0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "rush            0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "to              0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "tread           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "where           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "antony          0.0       0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0       0.0  \n",
      "angels     0.427365  0.427365  0.472707       0.0  \n",
      "fools      0.325248  0.325248  0.359756  0.359756  \n",
      "fear       0.427365  0.427365       0.0  0.472707  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from natsort import natsorted\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#preprocessing\n",
    "       \n",
    "files_name=natsorted(os.listdir('files'))\n",
    "document_of_terms=[]\n",
    "for files in files_name:\n",
    "    with open(f'files/{files}','r') as f:\n",
    "        document=f.read()\n",
    "        \n",
    "         \n",
    "    tokenized_documents=word_tokenize(document)\n",
    "    terms=[]\n",
    "    for word in tokenized_documents:\n",
    "            terms.append(word)\n",
    "    document_of_terms.append(terms)\n",
    "\n",
    "print('                                               *****    Documents in  Terms   *****                                                                        \\n    '\n",
    "    ,  document_of_terms,'\\n')                        \n",
    "\n",
    "#stemming \n",
    "stemmer=PorterStemmer()\n",
    "document_of_stemms=[]\n",
    "for terms in document_of_terms:\n",
    "     for word in terms :\n",
    "         stemmed_terms=[stemmer.stem(word)]\n",
    "         document_of_stemms.append(stemmed_terms)\n",
    "\n",
    "print('                                               *****     Stemmed Terms   *****                                                                        \\n    '\n",
    "    ,  document_of_stemms,'\\n')        \n",
    "\n",
    "#positional_index\n",
    "\n",
    "document_number = 0\n",
    "positional_index = {}\n",
    "\n",
    "print() \n",
    "print(\"                                               *****     positions    *****                                       \\n   \")\n",
    "for document in document_of_terms:\n",
    "    for positional, term in enumerate(document):\n",
    "        if term in positional_index:\n",
    "            positional_index[term][0] = positional_index[term][0] + 1\n",
    "\n",
    "            if document_number in positional_index[term][1]:\n",
    "                positional_index[term][1][document_number].append(positional)\n",
    "            else:\n",
    "                positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "        else:\n",
    "            positional_index[term] = []\n",
    "            positional_index[term].append(1)\n",
    "            positional_index[term].append({})\n",
    "            positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "    document_number += 1\n",
    "    \n",
    "\n",
    "print(positional_index,'\\n')\n",
    "\n",
    "\n",
    "#query_preprocessing\n",
    "\n",
    "query=input('put query here:')\n",
    "\n",
    "final_list=[[]for i in range (10)]\n",
    "print('                                    ***** all response list *****                                                     ')\n",
    "for word in query.split():    \n",
    "    if word in positional_index.keys():\n",
    "        for key in positional_index[word][1].keys():\n",
    "            \n",
    "            if final_list[key]!=[]:\n",
    "                \n",
    "                 if final_list[key][-1] == positional_index[word][1][key][0]-1:\n",
    "                        final_list[key].append(positional_index[word][1][key][0])\n",
    "        \n",
    "            else:\n",
    "                 final_list[key].append(positional_index[word][1][key][0])\n",
    "            \n",
    "print(final_list,'\\n')\n",
    "\n",
    "print('                                  *****response list to query*****                                              ')\n",
    "for position,list in enumerate(final_list,start=1):\n",
    "    if len(list)==len(query.split()):\n",
    "      print(position,list)     \n",
    "\n",
    "\n",
    "\n",
    "#find tf and wtf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "all_words=[]\n",
    "for doc in document_of_terms:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    " #tf       \n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(all_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word]+=1\n",
    "    return words_found\n",
    "\n",
    "term_freq=pd.DataFrame(get_term_freq(document_of_terms[0]).values(),index=get_term_freq(document_of_terms[0]).keys())              \n",
    "print('                                  *****term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)):\n",
    "    term_freq[i]=get_term_freq(document_of_terms[i]).values()\n",
    "    \n",
    "term_freq.columns=['doc'+str(i) for i in range (1,11)]    \n",
    "print(term_freq)     \n",
    "\n",
    "#wtf\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x>0:\n",
    "      return math.log(x)+1\n",
    "    return 0\n",
    "     \n",
    "print('                                  ***** weighted term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)+1):\n",
    "    term_freq['doc'+str(i)]= term_freq['doc'+str(i)].apply(get_weighted_term_freq) \n",
    "    \n",
    "print(term_freq,'\\n')\n",
    "print()\n",
    " \n",
    "#idf and tf*idf\n",
    " \n",
    "tfd=pd.DataFrame(columns=['df','idf'])\n",
    "\n",
    "print('                                  *****        IDF          *****                                              ')\n",
    "for i in range(len(term_freq)):\n",
    "    \n",
    "    frequancy=term_freq.iloc[i].values.sum()\n",
    "    \n",
    "    tfd.loc[i,'df']=frequancy\n",
    "    tfd.loc[i,'idf']=math.log10(10/(float(frequancy)))\n",
    "    \n",
    "tfd.index=term_freq.index\n",
    "    \n",
    "print(tfd)\n",
    "\n",
    "# tf*idf\n",
    "\n",
    "tf_idf=term_freq.multiply(tfd['idf'],axis=0)\n",
    "\n",
    "print('                                  *****         TF*IDF             *****                                              ')\n",
    "print()      \n",
    "print(tf_idf)\n",
    "\n",
    "\n",
    "# doc length\n",
    "\n",
    "def get_doc_len(col):\n",
    "    return np.sqrt(tf_idf[col].apply(lambda x:x**2).sum())\n",
    "\n",
    "doc_len=pd.DataFrame()\n",
    "for col in tf_idf.columns:\n",
    "    doc_len.loc['length', col+'__length']=get_doc_len(col)   \n",
    "print('                                  *****         Doc Length             *****                                              ') \n",
    "print(doc_len,'\\n')    \n",
    "\n",
    "\n",
    "\n",
    "# normalization\n",
    "norm_tf_idf= tf_idf.divide(doc_len.values[0],axis=1)\n",
    "print('                                  *****        Normalized TF*IDF           *****                                              ')\n",
    "print()\n",
    "print(norm_tf_idf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get query from user\n",
    "\n",
    "input_q=input('write your query:')\n",
    "\n",
    "print(input_q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_tf(x):\n",
    "    try:\n",
    "        return math.log10(x)+1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query['idf'].loc[input_q.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2.loc[input_q.split()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores={}\n",
    "for col in product2.columns:\n",
    "    if 0 in product2[col].loc[input_q.split()].values:\n",
    "        pass\n",
    "    else:\n",
    "        scores[col]=product2[col].sum()\n",
    "        \n",
    "scores        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2[scores.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2[scores.keys()].loc[input_q.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_res=product2[scores.keys()]\n",
    "\n",
    "prod_res.sum()\n",
    "\n",
    "final_score=sorted(scores.items(),key=lambda x:x[1],reverse=True)\n",
    "\n",
    "for doc in final_score:\n",
    "    print(doc[0],end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
