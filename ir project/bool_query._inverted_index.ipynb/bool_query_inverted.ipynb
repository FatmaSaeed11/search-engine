{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               *****    Documents in  Terms   *****                                                                        \n",
      "     [['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser'], ['antony', 'brutus', 'caeser', 'calpurnia'], ['mercy', 'worser'], ['brutus', 'caeser', 'mercy', 'worser'], ['caeser', 'mercy', 'worser'], ['antony', 'caeser', 'mercy'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'in', 'rush', 'to', 'tread', 'where'], ['fools', 'fear', 'in', 'rush', 'to', 'tread', 'where']] \n",
      "\n",
      "                                               *****     Stemmed Terms   *****                                                                        \n",
      "     [['antoni'], ['brutu'], ['caeser'], ['cleopatra'], ['merci'], ['worser'], ['antoni'], ['brutu'], ['caeser'], ['calpurnia'], ['merci'], ['worser'], ['brutu'], ['caeser'], ['merci'], ['worser'], ['caeser'], ['merci'], ['worser'], ['antoni'], ['caeser'], ['merci'], ['angel'], ['fool'], ['fear'], ['in'], ['rush'], ['to'], ['tread'], ['where'], ['angel'], ['fool'], ['fear'], ['in'], ['rush'], ['to'], ['tread'], ['where'], ['angel'], ['fool'], ['in'], ['rush'], ['to'], ['tread'], ['where'], ['fool'], ['fear'], ['in'], ['rush'], ['to'], ['tread'], ['where']] \n",
      "\n",
      "\n",
      "                                               *****     positions    *****                                       \n",
      "   \n",
      "{'antony': [3, {0: [0], 1: [0], 5: [0]}], 'brutus': [3, {0: [1], 1: [1], 3: [0]}], 'caeser': [5, {0: [2], 1: [2], 3: [1], 4: [0], 5: [1]}], 'cleopatra': [1, {0: [3]}], 'mercy': [5, {0: [4], 2: [0], 3: [2], 4: [1], 5: [2]}], 'worser': [4, {0: [5], 2: [1], 3: [3], 4: [2]}], 'calpurnia': [1, {1: [3]}], 'angels': [3, {6: [0], 7: [0], 8: [0]}], 'fools': [4, {6: [1], 7: [1], 8: [1], 9: [0]}], 'fear': [3, {6: [2], 7: [2], 9: [1]}], 'in': [4, {6: [3], 7: [3], 8: [2], 9: [2]}], 'rush': [4, {6: [4], 7: [4], 8: [3], 9: [3]}], 'to': [4, {6: [5], 7: [5], 8: [4], 9: [4]}], 'tread': [4, {6: [6], 7: [6], 8: [5], 9: [5]}], 'where': [4, {6: [7], 7: [7], 8: [6], 9: [6]}]} \n",
      "\n",
      "                                    ***** all response list *****                                                     \n",
      "[[0, 1], [0, 1], [], [0], [], [0], [], [], [], []] \n",
      "\n",
      "                                  *****response list to query*****                                              \n",
      "1 [0, 1]\n",
      "2 [0, 1]\n",
      "                                  *****term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony        1     1     0     0     0     1     0     0     0      0\n",
      "brutus        1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "mercy         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angels        0     0     0     0     0     0     1     1     1      0\n",
      "fools         0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "                                  ***** weighted term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutus      1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "mercy       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angels      0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fools       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0 \n",
      "\n",
      "\n",
      "                                  *****        IDF          *****                                              \n",
      "            df       idf\n",
      "antony     3.0  0.522879\n",
      "brutus     3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "mercy      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angels     3.0  0.522879\n",
      "fools      4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "                                  *****         TF*IDF             *****                                              \n",
      "\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antony     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutus     0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "mercy       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angels          0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fools           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antony          0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angels     0.522879  0.522879       0.0  \n",
      "fools       0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n",
      "                                  *****         Doc Length             *****                                              \n",
      "        doc1__length  doc2__length  doc3__length  doc4__length  doc5__length  \\\n",
      "length      1.373462      1.279618      0.498974      0.782941      0.582747   \n",
      "\n",
      "        doc6__length  doc7__length  doc8__length  doc9__length  doc10__length  \n",
      "length       0.67427      1.223496      1.223496      1.106137       1.106137   \n",
      "\n",
      "                                  *****        Normalized TF*IDF           *****                                              \n",
      "\n",
      "               doc1      doc2      doc3      doc4      doc5      doc6  \\\n",
      "antony     0.380701  0.408621       0.0       0.0       0.0  0.775474   \n",
      "brutus     0.380701  0.408621       0.0  0.667839       0.0       0.0   \n",
      "caeser     0.219176   0.23525       0.0  0.384486   0.51657  0.446453   \n",
      "cleopatra  0.728087       0.0       0.0       0.0       0.0       0.0   \n",
      "mercy      0.219176       0.0  0.603298  0.384486   0.51657  0.446453   \n",
      "worser     0.289735       0.0  0.797516  0.508263  0.682869       0.0   \n",
      "calpurnia       0.0  0.781483       0.0       0.0       0.0       0.0   \n",
      "angels          0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "fools           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "fear            0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "in              0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "rush            0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "to              0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "tread           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "where           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "\n",
      "               doc7      doc8      doc9     doc10  \n",
      "antony          0.0       0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0       0.0  \n",
      "angels     0.427365  0.427365  0.472707       0.0  \n",
      "fools      0.325248  0.325248  0.359756  0.359756  \n",
      "fear       0.427365  0.427365       0.0  0.472707  \n",
      "in         0.325248  0.325248  0.359756  0.359756  \n",
      "rush       0.325248  0.325248  0.359756  0.359756  \n",
      "to         0.325248  0.325248  0.359756  0.359756  \n",
      "tread      0.325248  0.325248  0.359756  0.359756  \n",
      "where      0.325248  0.325248  0.359756  0.359756  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from natsort import natsorted\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#preprocessing\n",
    "       \n",
    "files_name=natsorted(os.listdir('files'))\n",
    "document_of_terms=[]\n",
    "for files in files_name:\n",
    "    with open(f'files/{files}','r') as f:\n",
    "        document=f.read()\n",
    "        \n",
    "         \n",
    "    tokenized_documents=word_tokenize(document)\n",
    "    terms=[]\n",
    "    for word in tokenized_documents:\n",
    "            terms.append(word)\n",
    "    document_of_terms.append(terms)\n",
    "\n",
    "print('                                               *****    Documents in  Terms   *****                                                                        \\n    '\n",
    "    ,  document_of_terms,'\\n')                        \n",
    "\n",
    "#stemming \n",
    "stemmer=PorterStemmer()\n",
    "document_of_stemms=[]\n",
    "for terms in document_of_terms:\n",
    "     for word in terms :\n",
    "         stemmed_terms=[stemmer.stem(word)]\n",
    "         document_of_stemms.append(stemmed_terms)\n",
    "\n",
    "print('                                               *****     Stemmed Terms   *****                                                                        \\n    '\n",
    "    ,  document_of_stemms,'\\n')        \n",
    "\n",
    "#positional_index\n",
    "\n",
    "document_number = 0\n",
    "positional_index = {}\n",
    "\n",
    "print() \n",
    "print(\"                                               *****     positions    *****                                       \\n   \")\n",
    "for document in document_of_terms:\n",
    "    for positional, term in enumerate(document):\n",
    "        if term in positional_index:\n",
    "            positional_index[term][0] = positional_index[term][0] + 1\n",
    "\n",
    "            if document_number in positional_index[term][1]:\n",
    "                positional_index[term][1][document_number].append(positional)\n",
    "            else:\n",
    "                positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "        else:\n",
    "            positional_index[term] = []\n",
    "            positional_index[term].append(1)\n",
    "            positional_index[term].append({})\n",
    "            positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "    document_number += 1\n",
    "    \n",
    "\n",
    "print(positional_index,'\\n')\n",
    "\n",
    "\n",
    "#query_preprocessing\n",
    "\n",
    "query=input('put query here:')\n",
    "\n",
    "final_list=[[]for i in range (10)]\n",
    "print('                                    ***** all response list *****                                                     ')\n",
    "for word in query.split():    \n",
    "    if word in positional_index.keys():\n",
    "        for key in positional_index[word][1].keys():\n",
    "            \n",
    "            if final_list[key]!=[]:\n",
    "                \n",
    "                 if final_list[key][-1] == positional_index[word][1][key][0]-1:\n",
    "                        final_list[key].append(positional_index[word][1][key][0])\n",
    "        \n",
    "            else:\n",
    "                 final_list[key].append(positional_index[word][1][key][0])\n",
    "            \n",
    "print(final_list,'\\n')\n",
    "\n",
    "print('                                  *****response list to query*****                                              ')\n",
    "for position,list in enumerate(final_list,start=1):\n",
    "    if len(list)==len(query.split()):\n",
    "      print(position,list)     \n",
    "\n",
    "\n",
    "\n",
    "#find tf and wtf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "all_words=[]\n",
    "for doc in document_of_terms:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    " #tf       \n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(all_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word]+=1\n",
    "    return words_found\n",
    "\n",
    "term_freq=pd.DataFrame(get_term_freq(document_of_terms[0]).values(),index=get_term_freq(document_of_terms[0]).keys())              \n",
    "print('                                  *****term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)):\n",
    "    term_freq[i]=get_term_freq(document_of_terms[i]).values()\n",
    "    \n",
    "term_freq.columns=['doc'+str(i) for i in range (1,11)]    \n",
    "print(term_freq)     \n",
    "\n",
    "#wtf\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x>0:\n",
    "      return math.log(x)+1\n",
    "    return 0\n",
    "     \n",
    "print('                                  ***** weighted term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)+1):\n",
    "    term_freq['doc'+str(i)]= term_freq['doc'+str(i)].apply(get_weighted_term_freq) \n",
    "    \n",
    "print(term_freq,'\\n')\n",
    "print()\n",
    " \n",
    "#idf and tf*idf\n",
    " \n",
    "tfd=pd.DataFrame(columns=['df','idf'])\n",
    "\n",
    "print('                                  *****        IDF          *****                                              ')\n",
    "for i in range(len(term_freq)):\n",
    "    \n",
    "    frequancy=term_freq.iloc[i].values.sum()\n",
    "    \n",
    "    tfd.loc[i,'df']=frequancy\n",
    "    tfd.loc[i,'idf']=math.log10(10/(float(frequancy)))\n",
    "    \n",
    "tfd.index=term_freq.index\n",
    "    \n",
    "print(tfd)\n",
    "\n",
    "# tf*idf\n",
    "\n",
    "tf_idf=term_freq.multiply(tfd['idf'],axis=0)\n",
    "\n",
    "print('                                  *****         TF*IDF             *****                                              ')\n",
    "print()      \n",
    "print(tf_idf)\n",
    "\n",
    "# doc length\n",
    "\n",
    "def get_doc_len(col):\n",
    "    return np.sqrt(tf_idf[col].apply(lambda x:x**2).sum())\n",
    "\n",
    "doc_len=pd.DataFrame()\n",
    "for col in tf_idf.columns:\n",
    "    doc_len.loc['length', col+'__length']=get_doc_len(col)   \n",
    "print('                                  *****         Doc Length             *****                                              ') \n",
    "print(doc_len,'\\n')    \n",
    "\n",
    "\n",
    "\n",
    "# normalization\n",
    "norm_tf_idf= tf_idf.divide(doc_len.values[0],axis=1)\n",
    "print('                                  *****        Normalized TF*IDF           *****                                              ')\n",
    "print()\n",
    "print(norm_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#stack sol for bool query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_query=\"foo OR bar AND NOT gazonk\"\n",
    "sql_keywords=[\"AND\",\"NOT\",\"OR\"]\n",
    "sql_query=[]\n",
    "for word in python_query.split(\" \"):\n",
    "    if word in sql_keywords:\n",
    "        sql_query+=[ word ]\n",
    "    else:\n",
    "        sql_query+=[\"dictkey='%s'\" % word]\n",
    "\n",
    "real_sql_query=\" \".join(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BoolQuery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, sq: \u001b[43mBoolQuery\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Performs a search from a given query in boolean retrieval model,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Supports AND queries only and returns sorted document ID's as result:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sq\u001b[38;5;241m.\u001b[39mis_empty():\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msearch(sq)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BoolQuery' is not defined"
     ]
    }
   ],
   "source": [
    "def search(self, sq: BoolQuery) -> list:\n",
    "\n",
    "    # Performs a search from a given query in boolean retrieval model,\n",
    "    # Supports AND queries only and returns sorted document ID's as result:\n",
    "\n",
    "    if sq.is_empty():\n",
    "        return super().search(sq)\n",
    "\n",
    "    terms = [self.index[term] for term in sq.get_terms() if term in self.index]\n",
    "    if not terms:\n",
    "        return []\n",
    "\n",
    "    # Iterate over posting lists and intersect:\n",
    "    result, terms = terms[0].pst_list, terms[1:]\n",
    "    while terms and result:\n",
    "        result = self.intersect(result, terms[0].pst_list)\n",
    "        terms = terms[1:]\n",
    "    return [p.id for p in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(p1: list, p2: list) -> list:\n",
    "\n",
    "    # Performs linear merge of 2x sorted lists of postings,\n",
    "    # Returns the intersection between them (== matched documents):\n",
    "\n",
    "    res, i, j = list(), 0, 0\n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if p1[i].id == p2[j].id:\n",
    "            res.append(p1[i])\n",
    "            i, j = i + 1, j + 1\n",
    "        elif p1[i].id < p2[j].id:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(list1, list2):\n",
    "    return list(set(list1).intersection(list2))\n",
    "def union(list1, list2):\n",
    "    return list(set(list1).union(list2))\n",
    "def notin(list1, list2):\n",
    "    return [filter(lambda x: x not in list1, sublist) for sublist in list2]\n",
    "\n",
    "#intersection(positional_index['fools'], intersection(positional_index['fear'], positional_index['angels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to use function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[1,3,4,7,8,10]\n",
    "list2=[5,7,4,8,10]\n",
    "list3=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x\u001b[38;5;241m=\u001b[39mintersection(list1,list2)\u001b[38;5;241m+\u001b[39m\u001b[43mnotin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlist3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (x)\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36mnotin\u001b[1;34m(list1, list2)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotin\u001b[39m(list1, list2):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlist1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msublist\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m list2]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "x=intersection(list1,list2)+notin(list2,list3)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "<>:20: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\future\\AppData\\Local\\Temp\\ipykernel_14332\\2260377334.py:20: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  if operation is 'OR':\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "query=input('write your query:')\n",
    "\n",
    "#query=\"fools OR fear  AND NOT angle\"\n",
    "\n",
    "result_set=set()\n",
    "operation=None\n",
    "\n",
    "for word in re.split(\" +(AND|OR) +\",query):\n",
    "    #word will be in ['foo', 'OR', 'bar', 'AND', 'NOT gazonk']\n",
    "\n",
    "    inverted=False # for \"NOT word\" operations\n",
    "\n",
    "    if word in ['AND','OR']:\n",
    "        operation=word\n",
    "        continue\n",
    "\n",
    "    if word.find('NOT ') == 0:\n",
    "        if operation== 'OR':\n",
    "        # generally \"OR NOT\" operation does not make sense, but if it does in your case, you \n",
    "        # should update this if() accordingly\n",
    "            continue\n",
    "\n",
    "        inverted=True\n",
    "        # the word is inverted!\n",
    "        realword=word[4:]\n",
    "    else:\n",
    "        realword=word\n",
    "\n",
    "    if operation is not None:\n",
    "         # now we need to match the key and the filenames it contains:\n",
    "        current_set=set(inverted_index[realword])\n",
    "\n",
    "        if operation == 'AND':\n",
    "            if inverted == True:\n",
    "                result_set -= current_set\n",
    "            else:\n",
    "                result_set &= current_set\n",
    "        elif operation == 'OR':\n",
    "            result_set |= current_set\n",
    "\n",
    "    operation=None\n",
    "\n",
    "print (result_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
