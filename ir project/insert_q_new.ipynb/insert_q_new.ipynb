{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              *****    Documents     ***** \n",
      "antony brutus caeser cleopatra mercy worser\n",
      "antony brutus caeser calpurnia \n",
      "mercy worser\n",
      "brutus caeser mercy worser\n",
      "caeser mercy worser\n",
      "antony caeser mercy \n",
      "angels fools fear in rush to tread where\n",
      "angels fools fear in rush to tread where\n",
      "angels fools in rush to tread where\n",
      "fools fear in rush to tread where\n",
      "                                               *****    Documents in  Terms   *****                                                                        \n",
      "     [['antony', 'brutus', 'caeser', 'cleopatra', 'mercy', 'worser'], ['antony', 'brutus', 'caeser', 'calpurnia'], ['mercy', 'worser'], ['brutus', 'caeser', 'mercy', 'worser'], ['caeser', 'mercy', 'worser'], ['antony', 'caeser', 'mercy'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'fear', 'in', 'rush', 'to', 'tread', 'where'], ['angels', 'fools', 'in', 'rush', 'to', 'tread', 'where'], ['fools', 'fear', 'in', 'rush', 'to', 'tread', 'where']] \n",
      "\n",
      "\n",
      "                                               *****     positions    *****                                       \n",
      "   \n",
      "{'antony': [3, {0: [0], 1: [0], 5: [0]}], 'brutus': [3, {0: [1], 1: [1], 3: [0]}], 'caeser': [5, {0: [2], 1: [2], 3: [1], 4: [0], 5: [1]}], 'cleopatra': [1, {0: [3]}], 'mercy': [5, {0: [4], 2: [0], 3: [2], 4: [1], 5: [2]}], 'worser': [4, {0: [5], 2: [1], 3: [3], 4: [2]}], 'calpurnia': [1, {1: [3]}], 'angels': [3, {6: [0], 7: [0], 8: [0]}], 'fools': [4, {6: [1], 7: [1], 8: [1], 9: [0]}], 'fear': [3, {6: [2], 7: [2], 9: [1]}], 'in': [4, {6: [3], 7: [3], 8: [2], 9: [2]}], 'rush': [4, {6: [4], 7: [4], 8: [3], 9: [3]}], 'to': [4, {6: [5], 7: [5], 8: [4], 9: [4]}], 'tread': [4, {6: [6], 7: [6], 8: [5], 9: [5]}], 'where': [4, {6: [7], 7: [7], 8: [6], 9: [6]}]} \n",
      "\n",
      "                                    ***** all response list *****                                                     \n",
      "[[], [], [], [], [], [], [1, 2], [1, 2], [1], [0, 1]] \n",
      "\n",
      "                                  *****response list to query*****                                              \n",
      "7 [1, 2]\n",
      "8 [1, 2]\n",
      "10 [0, 1]\n",
      "                                  *****term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony        1     1     0     0     0     1     0     0     0      0\n",
      "brutus        1     1     0     1     0     0     0     0     0      0\n",
      "caeser        1     1     0     1     1     1     0     0     0      0\n",
      "cleopatra     1     0     0     0     0     0     0     0     0      0\n",
      "mercy         1     0     1     1     1     1     0     0     0      0\n",
      "worser        1     0     1     1     1     0     0     0     0      0\n",
      "calpurnia     0     1     0     0     0     0     0     0     0      0\n",
      "angels        0     0     0     0     0     0     1     1     1      0\n",
      "fools         0     0     0     0     0     0     1     1     1      1\n",
      "fear          0     0     0     0     0     0     1     1     0      1\n",
      "in            0     0     0     0     0     0     1     1     1      1\n",
      "rush          0     0     0     0     0     0     1     1     1      1\n",
      "to            0     0     0     0     0     0     1     1     1      1\n",
      "tread         0     0     0     0     0     0     1     1     1      1\n",
      "where         0     0     0     0     0     0     1     1     1      1\n",
      "                                  ***** weighted term freq for each  term in doc*****                                              \n",
      "\n",
      "           doc1  doc2  doc3  doc4  doc5  doc6  doc7  doc8  doc9  doc10\n",
      "antony      1.0   1.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0    0.0\n",
      "brutus      1.0   1.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "caeser      1.0   1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "cleopatra   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "mercy       1.0   0.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0    0.0\n",
      "worser      1.0   0.0   1.0   1.0   1.0   0.0   0.0   0.0   0.0    0.0\n",
      "calpurnia   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0\n",
      "angels      0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    0.0\n",
      "fools       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "fear        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   0.0    1.0\n",
      "in          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "rush        0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "to          0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "tread       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0\n",
      "where       0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0    1.0 \n",
      "\n",
      "\n",
      "                                  *****        IDF          *****                                              \n",
      "            df       idf\n",
      "antony     3.0  0.522879\n",
      "brutus     3.0  0.522879\n",
      "caeser     5.0   0.30103\n",
      "cleopatra  1.0       1.0\n",
      "mercy      5.0   0.30103\n",
      "worser     4.0   0.39794\n",
      "calpurnia  1.0       1.0\n",
      "angels     3.0  0.522879\n",
      "fools      4.0   0.39794\n",
      "fear       3.0  0.522879\n",
      "in         4.0   0.39794\n",
      "rush       4.0   0.39794\n",
      "to         4.0   0.39794\n",
      "tread      4.0   0.39794\n",
      "where      4.0   0.39794\n",
      "                                  *****         TF*IDF             *****                                              \n",
      "\n",
      "               doc1      doc2     doc3      doc4     doc5      doc6      doc7  \\\n",
      "antony     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
      "brutus     0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
      "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
      "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
      "mercy       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
      "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
      "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
      "angels          0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "fools           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
      "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
      "\n",
      "               doc8      doc9     doc10  \n",
      "antony          0.0       0.0       0.0  \n",
      "brutus          0.0       0.0       0.0  \n",
      "caeser          0.0       0.0       0.0  \n",
      "cleopatra       0.0       0.0       0.0  \n",
      "mercy           0.0       0.0       0.0  \n",
      "worser          0.0       0.0       0.0  \n",
      "calpurnia       0.0       0.0       0.0  \n",
      "angels     0.522879  0.522879       0.0  \n",
      "fools       0.39794   0.39794   0.39794  \n",
      "fear       0.522879       0.0  0.522879  \n",
      "in          0.39794   0.39794   0.39794  \n",
      "rush        0.39794   0.39794   0.39794  \n",
      "to          0.39794   0.39794   0.39794  \n",
      "tread       0.39794   0.39794   0.39794  \n",
      "where       0.39794   0.39794   0.39794  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'doc0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\future\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'doc0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mf:\\fatma\\level 4\\IR\\ir project\\insert_q_new.ipynb\\insert_q_new.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m \u001b[39m# doc length\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m \u001b[39mdef get_documents_length(col):\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m \u001b[39m    return np.sqrt(tf_idf[col].apply(lambda x:x**2).sum())\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m \u001b[39mprint(norm_tf_idf, '\\n')\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m document_length\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m--> <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdoc\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_length\u001b[39m\u001b[39m'\u001b[39m:np\u001b[39m.\u001b[39msqrt(tf_idf[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdoc\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:x\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum()) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m                              \n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m },index\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m                                  *****         Doc Length             *****                                              \u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/fatma/level%204/IR/ir%20project/insert_q_new.ipynb/insert_q_new.ipynb#W0sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\future\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\future\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'doc0'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from natsort import natsorted\n",
    "from nltk.stem import PorterStemmer\n",
    "#preprocessing\n",
    "       \n",
    "files_name=natsorted(os.listdir('files'))\n",
    "print('                                              *****    Documents     ***** ' )\n",
    "document_of_terms=[]\n",
    "for files in files_name:\n",
    "    with open(f'files/{files}','r') as f:\n",
    "        document=f.read()\n",
    "        \n",
    "        print(document)\n",
    " \n",
    "    tokenized_documents=word_tokenize(document)\n",
    "    terms=[]\n",
    "    for word in tokenized_documents:\n",
    "            terms.append(word)\n",
    "    document_of_terms.append(terms)\n",
    "\n",
    "print('                                               *****    Documents in  Terms   *****                                                                        \\n    '\n",
    "    ,  document_of_terms,'\\n')                        \n",
    "\n",
    "######### \n",
    "#positional_index\n",
    "\n",
    "document_number = 0\n",
    "positional_index = {}\n",
    "\n",
    "print() \n",
    "print(\"                                               *****     positions    *****                                       \\n   \")\n",
    "for document in document_of_terms:\n",
    "    for positional, term in enumerate(document):\n",
    "        if term in positional_index:\n",
    "            positional_index[term][0] = positional_index[term][0] + 1\n",
    "\n",
    "            if document_number in positional_index[term][1]:\n",
    "                positional_index[term][1][document_number].append(positional)\n",
    "            else:\n",
    "                positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "        else:\n",
    "            positional_index[term] = []\n",
    "            positional_index[term].append(1)\n",
    "            positional_index[term].append({})\n",
    "            positional_index[term][1][document_number] = [positional]\n",
    "\n",
    "    document_number += 1\n",
    "    \n",
    "\n",
    "print(positional_index,'\\n')\n",
    "\n",
    "#query_preprocessing\n",
    "\n",
    "query='fools fear'\n",
    "\n",
    "final_list=[[]for i in range (10)]\n",
    "print('                                    ***** all response list *****                                                     ')\n",
    "for word in query.split():    \n",
    "    if word in positional_index.keys():\n",
    "        for key in positional_index[word][1].keys():\n",
    "            #print(key)\n",
    "            if final_list[key]!=[]:\n",
    "                \n",
    "                 if final_list[key][-1] == positional_index[word][1][key][0]-1:\n",
    "                        final_list[key].append(positional_index[word][1][key][0])\n",
    "        \n",
    "            else:\n",
    "                 final_list[key].append(positional_index[word][1][key][0])\n",
    "            \n",
    "print(final_list,'\\n')\n",
    "\n",
    "print('                                  *****response list to query*****                                              ')\n",
    "for position,list in enumerate(final_list,start=1):\n",
    "    if len(list)==len(query.split()):\n",
    "      print(position,list)     \n",
    "\n",
    "\n",
    "#find tf and wtf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "all_words=[]\n",
    "for doc in document_of_terms:\n",
    "    for word in doc:\n",
    "        all_words.append(word)\n",
    " #tf       \n",
    "def get_term_freq(doc):\n",
    "    words_found=dict.fromkeys(all_words,0)\n",
    "    for word in doc:\n",
    "        words_found[word]+=1\n",
    "    return words_found\n",
    "\n",
    "term_freq=pd.DataFrame(get_term_freq(document_of_terms[0]).values(),index=get_term_freq(document_of_terms[0]).keys())              \n",
    "print('                                  *****term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)):\n",
    "    term_freq[i]=get_term_freq(document_of_terms[i]).values()\n",
    "    \n",
    "term_freq.columns=['doc'+str(i) for i in range (1,11)]    \n",
    "print(term_freq)     \n",
    "\n",
    "#wtf\n",
    "\n",
    "def get_weighted_term_freq(x):\n",
    "    if x>0:\n",
    "      return math.log(x)+1\n",
    "    return 0\n",
    "     \n",
    "print('                                  ***** weighted term freq for each  term in doc*****                                              ')\n",
    "print()        \n",
    "for i in range(1,len(document_of_terms)+1):\n",
    "    term_freq['doc'+str(i)]= term_freq['doc'+str(i)].apply(get_weighted_term_freq) \n",
    "    \n",
    "print(term_freq,'\\n')\n",
    "print()\n",
    " \n",
    "#idf and tf*idf\n",
    " \n",
    "tfd=pd.DataFrame(columns=['df','idf'])\n",
    "\n",
    "print('                                  *****        IDF          *****                                              ')\n",
    "for i in range(len(term_freq)):\n",
    "    \n",
    "    frequancy=term_freq.iloc[i].values.sum()\n",
    "    \n",
    "    tfd.loc[i,'df']=frequancy\n",
    "    tfd.loc[i,'idf']=math.log10(10/(float(frequancy)))\n",
    "    \n",
    "tfd.index=term_freq.index\n",
    "    \n",
    "print(tfd)\n",
    "# tf*idf\n",
    "\n",
    "tf_idf=term_freq.multiply(tfd['idf'],axis=0)\n",
    "\n",
    "print('                                  *****         TF*IDF             *****                                              ')\n",
    "print()      \n",
    "print(tf_idf)\n",
    "# doc length\n",
    "\n",
    "\n",
    "def get_documents_length(col):\n",
    "    return np.sqrt(tf_idf[col].apply(lambda x:x**2).sum())\n",
    "\n",
    "\n",
    "for column in tf_idf.columns:\n",
    "    document_length.loc[0,column+'_len']=get_documents_length(column)\n",
    "print('                                  *****         Doc Length             *****                                              ') \n",
    "print(document_length,'\\n')    \n",
    "'''\n",
    "\n",
    "# normalized tf*idf\n",
    "norm_tf_idf = pd.DataFrame()\n",
    "def get_normalized(col, x):\n",
    "    try:\n",
    "        return x / document_length[col + '__len'].values[0]\n",
    "    except:\n",
    "        return 0\n",
    "for column in tf_idf.columns:\n",
    "    norm_tf_idf[column] = tf_idf[column].apply(lambda x: get_normalized(column, x))\n",
    "\n",
    "print('                                  *****        Normalized TF*IDF           *****                                              ')\n",
    "print(norm_tf_idf, '\\n')\n",
    "'''\n",
    "'''\n",
    "document_length=pd.DataFrame({\n",
    "    f'doc{i}_length':np.sqrt(tf_idf[f'doc{i}'].apply(lambda x:x**2).sum()) for i in range (0,10)\n",
    "                             \n",
    "},index=[0])\n",
    "print('                                  *****         Doc Length             *****                                              ') \n",
    "print()\n",
    "print(document_length,'\\n')\n",
    "'''\n",
    "\n",
    "norm_tf_idf= tf_idf.divide(document_length.values[0],axis=1)\n",
    "print('                                  *****        Normalized TF*IDF           *****                                              ')\n",
    "print()\n",
    "print(norm_tf_idf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antony brutus \n"
     ]
    }
   ],
   "source": [
    "# get query from user\n",
    "\n",
    "input_q=input('write your query:')\n",
    "\n",
    "print(input_q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_tf(x):\n",
    "    try:\n",
    "        return math.log10(x)+1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\future\\AppData\\Local\\Temp\\ipykernel_12844\\1340167131.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  query['norm'].iloc[i]=float(query['idf'].iloc[i])/math.sqrt(sum(query['idf'].values**2))\n",
      "C:\\Users\\future\\AppData\\Local\\Temp\\ipykernel_12844\\1340167131.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.7071067811865475' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  query['norm'].iloc[i]=float(query['idf'].iloc[i])/math.sqrt(sum(query['idf'].values**2))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "      <th>w_tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tf  w_tf       idf    tf_idf      norm\n",
       "antony      1   1.0  0.522879  0.522879  0.707107\n",
       "brutus      1   1.0  0.522879  0.522879  0.707107\n",
       "caeser      0   0.0       0.0       0.0  0.000000\n",
       "cleopatra   0   0.0       0.0       0.0  0.000000\n",
       "mercy       0   0.0       0.0       0.0  0.000000\n",
       "worser      0   0.0       0.0       0.0  0.000000\n",
       "calpurnia   0   0.0       0.0       0.0  0.000000\n",
       "angels      0   0.0       0.0       0.0  0.000000\n",
       "fools       0   0.0       0.0       0.0  0.000000\n",
       "fear        0   0.0       0.0       0.0  0.000000\n",
       "in          0   0.0       0.0       0.0  0.000000\n",
       "rush        0   0.0       0.0       0.0  0.000000\n",
       "to          0   0.0       0.0       0.0  0.000000\n",
       "tread       0   0.0       0.0       0.0  0.000000\n",
       "where       0   0.0       0.0       0.0  0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "query=pd.DataFrame(index=norm_tf_idf.index)\n",
    "query['tf']=[1 if x in input_q.split() else 0 for x in (norm_tf_idf.index)]\n",
    "\n",
    "query['w_tf']=query['tf'].apply(lambda x:get_w_tf(x))\n",
    "product=norm_tf_idf.multiply(query['w_tf'],axis=0)\n",
    "query['idf']=tfd['idf']*query['w_tf']\n",
    "query['tf_idf']=query['w_tf']*query['idf']\n",
    "query['norm']=0\n",
    "for i in range(len(query)):\n",
    "    query['norm'].iloc[i]=float(query['idf'].iloc[i])/math.sqrt(sum(query['idf'].values**2))\n",
    "\n",
    "product2=product.multiply(query['norm'],axis=0)   \n",
    "#product2\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "antony    0.522879\n",
       "brutus    0.522879\n",
       "Name: idf, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query['idf'].loc[input_q.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2691963968731551, 0.28893855150207176, 0.0, 0.0, 0.0,\n",
       "        0.5483426496621455, 0.0, 0.0, 0.0, 0.0],\n",
       "       [0.2691963968731551, 0.28893855150207176, 0.0,\n",
       "        0.47223369916907476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product2.loc[input_q.split()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc1': 0.5383927937463102, 'doc2': 0.5778771030041435}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores={}\n",
    "for col in product2.columns:\n",
    "    if 0 in product2[col].loc[input_q.split()].values:\n",
    "        pass\n",
    "    else:\n",
    "        scores[col]=product2[col].sum()\n",
    "        \n",
    "scores        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.269196</td>\n",
       "      <td>0.288939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.269196</td>\n",
       "      <td>0.288939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               doc1      doc2\n",
       "antony     0.269196  0.288939\n",
       "brutus     0.269196  0.288939\n",
       "caeser          0.0       0.0\n",
       "cleopatra       0.0       0.0\n",
       "mercy           0.0       0.0\n",
       "worser          0.0       0.0\n",
       "calpurnia       0.0       0.0\n",
       "angels          0.0       0.0\n",
       "fools           0.0       0.0\n",
       "fear            0.0       0.0\n",
       "in              0.0       0.0\n",
       "rush            0.0       0.0\n",
       "to              0.0       0.0\n",
       "tread           0.0       0.0\n",
       "where           0.0       0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product2[scores.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.269196</td>\n",
       "      <td>0.288939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.269196</td>\n",
       "      <td>0.288939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc1      doc2\n",
       "antony  0.269196  0.288939\n",
       "brutus  0.269196  0.288939"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product2[scores.keys()].loc[input_q.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2doc1"
     ]
    }
   ],
   "source": [
    "prod_res=product2[scores.keys()]\n",
    "\n",
    "prod_res.sum()\n",
    "\n",
    "final_score=sorted(scores.items(),key=lambda x:x[1],reverse=True)\n",
    "\n",
    "for doc in final_score:\n",
    "    print(doc[0],end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
